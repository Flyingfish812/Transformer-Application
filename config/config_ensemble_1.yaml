# config file for vision transformer

model_1:
  name: 'VisionTransformer'
  load_weights: False
  image_size: 360
  patch_size: 36
  num_layers: 12
  num_heads: 16
  hidden_dim: 32
  mlp_dim: 256
  num_classes: 64800  # Assuming 180*360
  path: 'model/sst_vit_273.pth'

model_2:
  name: 'ResNet'
  load_weights: False
  size: 18
  path: 'model/sst_res_273.pth'

model_3:
  model:
  name: 'CNN'
  load_weights: False
  channels: 48
  kernel_size: 7
  padding: 3
  path: 'model/sst_cnn_273.pth'

model:
  name: 'EnsembleModel'
  method: 'blending'
  load_weights: False
  num_models: 3

data:
  file_path: './sst_weekly.mat'

training:
  num_epochs: 3
  fig_num: 1914
  batch_size: 32
  learning_rate: 0.01
  start_point: 0
  sensor_num: [100]
  sensor_seed: [4]
  sigma: 0.0
  input_type: "VIT"

testing:
  fig_num: 256
  batch_size: 32
  start_point: 1656
  norm: "L2"
  sensor_num: [10,20,30,50,100]
  sensor_seed: [4,9]
  sigma: 0.0
  input_type: "VIT"

device:
  prefer_gpu: true

output:
  model_result: 'sst_vit_result_2'
  model_save_path: 'model/sst_ensemble_test_2.pth'
